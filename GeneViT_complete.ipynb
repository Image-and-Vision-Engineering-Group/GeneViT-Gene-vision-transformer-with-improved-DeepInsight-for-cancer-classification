{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This file contains the code of two stage processing of the data.\n",
        "1. Improved DeepInsight method to generate gene expression data image with channel wise explanation (Original DeepInsight code can be accessed from the folloing link   https://alok-ai-lab.github.io/DeepInsight/)\n",
        "2.Classification method of the generated image data by the vision Transformer\n",
        "(Original Vision Transformer code can be accessed from the following link https://keras.io/examples/vision/image_classification_with_vision_transformer/)"
      ],
      "metadata": {
        "id": "4vfNwiVOjfIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.manifold import TSNE\n",
        "from scipy.spatial import ConvexHull\n",
        "from matplotlib import pyplot as plt\n",
        "import inspect\n",
        "#from pyDeepInsight import ImageTransformer, LogScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "class ImageTransformer:\n",
        "    \"\"\"Transform features to an image matrix using dimensionality reduction\n",
        "    This class takes in data normalized between 0 and 1 and converts it to a\n",
        "    CNN compatible 'image' matrix\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feature_extractor='tsne', pixels=100,\n",
        "                 random_state=None, n_jobs=-1):\n",
        "        \"\"\"Generate an ImageTransformer instance\n",
        "        Args:\n",
        "            feature_extractor: string of value ('tsne', 'pca', 'kpca') or a\n",
        "                class instance with method `fit_transform` that returns a\n",
        "                2-dimensional array of extracted features.\n",
        "            pixels: int (square matrix) or tuple of ints (height, width) that\n",
        "                defines the size of the image matrix.\n",
        "            random_state: int or RandomState. Determines the random number\n",
        "                generator, if present, of a string defined feature_extractor.\n",
        "            n_jobs: The number of parallel jobs to run for a string defined\n",
        "                feature_extractor.\n",
        "        \"\"\"\n",
        "        self.random_state = random_state\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        if isinstance(feature_extractor, str):\n",
        "            fe = feature_extractor.casefold()\n",
        "            if fe == 'tsne'.casefold():\n",
        "                fe = TSNE(\n",
        "                    n_components=2, metric='cosine',\n",
        "                    random_state=self.random_state)\n",
        "            elif fe == 'pca'.casefold():\n",
        "                fe = PCA(n_components=2,\n",
        "                         random_state=self.random_state)\n",
        "            elif fe == 'kpca'.casefold():\n",
        "                fe = KernelPCA(\n",
        "                    n_components=2, kernel='rbf',\n",
        "                    random_state=self.random_state,\n",
        "                    n_jobs=self.n_jobs)\n",
        "            else:\n",
        "                raise ValueError((\"Feature extraction method '{}' not accepted\"\n",
        "                                  ).format(feature_extractor))\n",
        "            self._fe = fe\n",
        "        elif hasattr(feature_extractor, 'fit_transform') and \\\n",
        "                inspect.ismethod(feature_extractor.fit_transform):\n",
        "            self._fe = feature_extractor\n",
        "        else:\n",
        "            raise TypeError('Parameter feature_extractor is not a '\n",
        "                            'string nor has method \"fit_transform\"')\n",
        "\n",
        "        if isinstance(pixels, int):\n",
        "            pixels = (pixels, pixels)\n",
        "        self._pixels = pixels\n",
        "        self._xrot = None\n",
        "\n",
        "    def fit(self, X, y=None, plot=False):\n",
        "        \"\"\"Train the image transformer from the training set (X)\n",
        "        Args:\n",
        "            X: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
        "            y: Ignored. Present for continuity with scikit-learn\n",
        "            plot: boolean of whether to produce a scatter plot showing the\n",
        "                feature reduction, hull points, and minimum bounding rectangle\n",
        "        Returns:\n",
        "            self: object\n",
        "        \"\"\"\n",
        "        # perform dimensionality reduction\n",
        "        x_new = self._fe.fit_transform(X.T)\n",
        "        # get the convex hull for the points\n",
        "        chvertices = ConvexHull(x_new).vertices\n",
        "        hull_points = x_new[chvertices]\n",
        "        # determine the minimum bounding rectangle\n",
        "        mbr, mbr_rot = self._minimum_bounding_rectangle(hull_points)\n",
        "        # rotate the matrix\n",
        "        # save the rotated matrix in case user wants to change the pixel size\n",
        "        self._xrot = np.dot(mbr_rot, x_new.T).T\n",
        "        # determine feature coordinates based on pixel dimension\n",
        "        self._calculate_coords()\n",
        "        # plot rotation diagram if requested\n",
        "        if plot is True:\n",
        "            plt.scatter(x_new[:, 0], x_new[:, 1], s=1,\n",
        "                        cmap=plt.cm.get_cmap(\"jet\", 10), alpha=0.2)\n",
        "            plt.fill(x_new[chvertices, 0], x_new[chvertices, 1],\n",
        "                     edgecolor='r', fill=False)\n",
        "            plt.fill(mbr[:, 0], mbr[:, 1], edgecolor='g', fill=False)\n",
        "            plt.gca().set_aspect('equal', adjustable='box')\n",
        "            plt.show()\n",
        "        return self\n",
        "\n",
        "    @property\n",
        "    def pixels(self):\n",
        "        \"\"\"The image matrix dimensions\n",
        "        Returns:\n",
        "            tuple: the image matrix dimensions (height, width)\n",
        "        \"\"\"\n",
        "        return self._pixels\n",
        "\n",
        "    @pixels.setter\n",
        "    def pixels(self, pixels):\n",
        "        \"\"\"Set the image matrix dimension\n",
        "        Args:\n",
        "            pixels: int or tuple with the dimensions (height, width)\n",
        "            of the image matrix\n",
        "        \"\"\"\n",
        "        if isinstance(pixels, int):\n",
        "            pixels = (pixels, pixels)\n",
        "        self._pixels = pixels\n",
        "        # recalculate coordinates if already fit\n",
        "        if hasattr(self, '_coords'):\n",
        "            self._calculate_coords()\n",
        "\n",
        "    def _calculate_coords(self):\n",
        "        \"\"\"Calculate the matrix coordinates of each feature based on the\n",
        "        pixel dimensions.\n",
        "        \"\"\"\n",
        "        ax0_coord = np.digitize(\n",
        "            self._xrot[:, 0],\n",
        "            bins=np.linspace(min(self._xrot[:, 0]), max(self._xrot[:, 0]),\n",
        "                             self._pixels[0])\n",
        "        ) - 1\n",
        "        ax1_coord = np.digitize(\n",
        "            self._xrot[:, 1],\n",
        "            bins=np.linspace(min(self._xrot[:, 1]), max(self._xrot[:, 1]),\n",
        "                             self._pixels[1])\n",
        "        ) - 1\n",
        "        self._coords = np.stack((ax0_coord, ax1_coord), axis=1)\n",
        "\n",
        "    def transform(self, X, format='scalar', empty_value=0):\n",
        "        \"\"\"Transform the input matrix into image matrices\n",
        "        Args:\n",
        "            X: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
        "                where n_features matches the training set.\n",
        "            format: The format of the image matrix to return. 'scalar' return a\n",
        "                array of shape (M, N). 'rgb' returns an numpy.ndarray of shape\n",
        "                (M, N, 3) that is compatible with PIL.\n",
        "            empty_value: numeric value to fill elements where no features are\n",
        "                mapped. Default = 0.\n",
        "        Returns:\n",
        "            A list of n_samples numpy matrices of dimensions set by\n",
        "            the pixel parameter\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        img_coords = pd.DataFrame(np.vstack((\n",
        "            self._coords.T,\n",
        "            X\n",
        "        )).T).groupby([0, 1], as_index=False).mean()\n",
        "\n",
        "\n",
        "        img_matrices = []\n",
        "        blank_mat = np.zeros(self._pixels)\n",
        "        if empty_value != 0:\n",
        "            blank_mat[:] = empty_value\n",
        "        for z in range(2, img_coords.shape[1]):\n",
        "            img_matrix = blank_mat.copy()\n",
        "            img_matrix[img_coords[0].astype(int),\n",
        "                       img_coords[1].astype(int)] = img_coords[z]\n",
        "            img_matrices.append(img_matrix)\n",
        "\n",
        "\n",
        "        if format=='rgb':\n",
        "            img_matrices = np.array([self._mat_to_rgb(m) for m in img_matrices])\n",
        "        elif format=='scalar':\n",
        "            img_matrices = np.stack(img_matrices)\n",
        "        else:\n",
        "            raise ValueError((\"'{}' not accepted for parameter 'format'\")\n",
        "                             .format(format))\n",
        "\n",
        "        return img_matrices\n",
        "\n",
        "    def fit_transform(self, X, **kwargs):\n",
        "        \"\"\"Train the image transformer from the training set (X) and return\n",
        "        the transformed data.\n",
        "        Args:\n",
        "            X: {array-like, sparse matrix} of shape (n_samples, n_features)\n",
        "        Returns:\n",
        "            A list of n_samples numpy matrices of dimensions set by\n",
        "            the pixel parameter\n",
        "        \"\"\"\n",
        "        self.fit(X)\n",
        "        return self.transform(X, **kwargs)\n",
        "\n",
        "    def feature_density_matrix(self):\n",
        "        \"\"\"Generate image matrix with feature counts per pixel\n",
        "        Returns:\n",
        "            img_matrix (ndarray): matrix with feature counts per pixel\n",
        "        \"\"\"\n",
        "        fdmat = np.zeros(self._pixels)\n",
        "        np.add.at(fdmat, tuple(self._coords.T), 1)\n",
        "        return fdmat\n",
        "\n",
        "    def coords(self):\n",
        "        \"\"\"Get feature coordinates\n",
        "        Returns:\n",
        "            ndarray: the pixel coordinates for features\n",
        "        \"\"\"\n",
        "        return self._coords.copy()\n",
        "\n",
        "    @staticmethod\n",
        "    def _minimum_bounding_rectangle(hull_points):\n",
        "        \"\"\"Find the smallest bounding rectangle for a set of points.\n",
        "        Modified from JesseBuesking at https://stackoverflow.com/a/33619018\n",
        "        Returns a set of points representing the corners of the bounding box.\n",
        "        Args:\n",
        "            hull_points : an nx2 matrix of hull coordinates\n",
        "        Returns:\n",
        "            (tuple): tuple containing\n",
        "                coords (ndarray): coordinates of the corners of the rectangle\n",
        "                rotmat (ndarray): rotation matrix to align edges of rectangle\n",
        "                    to x and y\n",
        "        \"\"\"\n",
        "\n",
        "        pi2 = np.pi / 2\n",
        "        # calculate edge angles\n",
        "        edges = hull_points[1:] - hull_points[:-1]\n",
        "        angles = np.arctan2(edges[:, 1], edges[:, 0])\n",
        "        angles = np.abs(np.mod(angles, pi2))\n",
        "        angles = np.unique(angles)\n",
        "        # find rotation matrices\n",
        "        rotations = np.vstack([\n",
        "            np.cos(angles),\n",
        "            -np.sin(angles),\n",
        "            np.sin(angles),\n",
        "            np.cos(angles)]).T\n",
        "        rotations = rotations.reshape((-1, 2, 2))\n",
        "        # apply rotations to the hull\n",
        "        rot_points = np.dot(rotations, hull_points.T)\n",
        "        # find the bounding points\n",
        "        min_x = np.nanmin(rot_points[:, 0], axis=1)\n",
        "        max_x = np.nanmax(rot_points[:, 0], axis=1)\n",
        "        min_y = np.nanmin(rot_points[:, 1], axis=1)\n",
        "        max_y = np.nanmax(rot_points[:, 1], axis=1)\n",
        "        # find the box with the best area\n",
        "        areas = (max_x - min_x) * (max_y - min_y)\n",
        "        best_idx = np.argmin(areas)\n",
        "        # return the best box\n",
        "        x1 = max_x[best_idx]\n",
        "        x2 = min_x[best_idx]\n",
        "        y1 = max_y[best_idx]\n",
        "        y2 = min_y[best_idx]\n",
        "        rotmat = rotations[best_idx]\n",
        "        # generate coordinates\n",
        "        coords = np.zeros((4, 2))\n",
        "        coords[0] = np.dot([x1, y2], rotmat)\n",
        "        coords[1] = np.dot([x2, y2], rotmat)\n",
        "        coords[2] = np.dot([x2, y1], rotmat)\n",
        "        coords[3] = np.dot([x1, y1], rotmat)\n",
        "\n",
        "        return coords, rotmat\n",
        "\n",
        "    @staticmethod\n",
        "    def _mat_to_rgb(mat):\n",
        "        \"\"\"Convert image matrix to numpy rgb format\n",
        "        Args:\n",
        "            mat: {array-like} (M, N)\n",
        "        Returns:\n",
        "            An numpy.ndarry (M, N, 3) with orignal values repeated across\n",
        "            RGB channels.\n",
        "        \"\"\"\n",
        "        return np.repeat(mat[:, :, np.newaxis], 3, axis=2)\n",
        "\n",
        "\n",
        "class LogScaler:\n",
        "    \"\"\"Log normalize and scale data\n",
        "    Log normalization and scaling procedure as described as norm-2 in the\n",
        "    DeepInsight paper supplementary information.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self._min0 = None\n",
        "        self._max = None\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self._min0 = X.min(axis=0)\n",
        "        self._max = np.log(X + np.abs(self._min0) + 1).max()\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        self._min0 = X.min(axis=0)\n",
        "        X_norm = np.log(X + np.abs(self._min0) + 1)\n",
        "        self._max = X_norm.max()\n",
        "        return X_norm / self._max\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        X_norm = np.log(X + np.abs(self._min0) + 1).clip(0, None)\n",
        "        return (X_norm / self._max).clip(0, 1)"
      ],
      "metadata": {
        "id": "b6kHFBpjeXxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jbVA7hpV77Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us2LaaZD7PmT"
      },
      "outputs": [],
      "source": [
        "# Read the data from drive\n",
        "df = pd.read_csv('/content/drive/MyDrive/New_MLL.csv')\n",
        "# Note: For your data, you need to use the link of your Google drive\n",
        "\n",
        "df = df.drop(['Unnamed: 0'],axis=1) # this line is used in my data one can remove for their data\n",
        "data= df.values\n",
        "X = data[:,:-1]\n",
        "YY = data[:,-1]\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_scl = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scl, YY, test_size=0.2, random_state=23, stratify=YY)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9_n-oOx7PmU"
      },
      "outputs": [],
      "source": [
        "ln = LogScaler()\n",
        "X_train_norm = ln.fit_transform(X_train)\n",
        "X_test_norm = ln.transform(X_test)\n",
        "X_norm = ln.transform(X_scl)\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne = TSNE(n_components=2, perplexity=64, metric='cosine',\n",
        "            random_state=1701)\n",
        "\n",
        "it = ImageTransformer(feature_extractor=tsne, pixels=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQBmpJHE7PmV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5, 5))\n",
        "_ = it.fit(X_norm, plot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_UK9yEk7PmV"
      },
      "outputs": [],
      "source": [
        "fdm = it.feature_density_matrix()\n",
        "data_pix=fdm\n",
        "data_pix.max()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image genrated by original deepInsight\n",
        "plt.figure(figsize=(5, 5))\n",
        "_ = it.fit(X_train_norm, plot=True)\n",
        "px_sizes = [25, (25, 50), 50, 100]\n",
        "\n",
        "fig, ax = plt.subplots(1, len(px_sizes), figsize=(25, 7))\n",
        "for ix, px in enumerate(px_sizes):\n",
        "    it.pixels = px\n",
        "    fdm = it.feature_density_matrix()\n",
        "\n",
        "    fdm[fdm == 0] = np.nan\n",
        "    cax = sns.heatmap(fdm, cmap=\"viridis\", linewidth=0.01,\n",
        "                      linecolor=\"lightgrey\", square=True,\n",
        "                      ax=ax[ix], cbar=False)\n",
        "    cax.set_title('Dim {} x {}'.format(*it.pixels))\n",
        "    for _, spine in cax.spines.items():\n",
        "        spine.set_visible(True)\n",
        "    cax.xaxis.set_major_locator(ticker.MultipleLocator(5))\n",
        "    cax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
        "plt.tight_layout()\n",
        "\n",
        "it.pixels =64"
      ],
      "metadata": {
        "id": "ajAhKT5w_tDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_pix.sum()\n",
        "aaa=it.coords().T\n",
        "aaa.shape\n",
        "a_i=pd.DataFrame(np.vstack((aaa,X_norm)).T)\n",
        "ai=pd.DataFrame(np.vstack((aaa,X_norm)).T).groupby([0, 1], as_index=False)\n",
        "ai.groups\n",
        "ai"
      ],
      "metadata": {
        "id": "POoOEu4ogoyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The following piece of the code is for Improved DeepInsight method with  channel wise expansion."
      ],
      "metadata": {
        "id": "WcOsXQEBecGb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PHvXdpF7PmY"
      },
      "outputs": [],
      "source": [
        "aaa=it.coords().T\n",
        "aai=pd.DataFrame(np.vstack((aaa,X_norm)).T).groupby([0, 1], as_index=False).agg(pd.Series.tolist)\n",
        "aai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XzU5skA7PmY"
      },
      "outputs": [],
      "source": [
        "pxm=64 # for image size of 64X64\n",
        "emp_value=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5KxHrAF7PmY"
      },
      "outputs": [],
      "source": [
        "# create diffrent channels data\n",
        "def newsamp(dfn,s_n):\n",
        "    split_df = pd.DataFrame(dfn[s_n].tolist())\n",
        "    split_df\n",
        "    split_df[(split_df.select_dtypes(include=['number']) != 0).any(axis=1)]\n",
        "    avg_no=split_df.shape[1]\n",
        "    ave_data = split_df.copy()\n",
        "    ave_data['average'] = ave_data.mean(numeric_only=True, axis=1)\n",
        "    row=ave_data.shape[0]\n",
        "    clo=ave_data.shape[1]\n",
        "    AA=np.array(ave_data)\n",
        "    for i in range(row):\n",
        "        for j in range(clo):\n",
        "            if np.isnan(AA[i][j]):\n",
        "                AA[i][j] = AA[i][avg_no]\n",
        "    AA=np.delete(AA, avg_no, 1)\n",
        "    dfn = dfn.drop(s_n, axis=1)\n",
        "    df_new = pd.DataFrame(AA, columns = [i for i in range(2,AA.shape[1]+2)])\n",
        "    new_df = pd.concat([dfn, df_new], axis=1)\n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idPebuK37PmZ"
      },
      "outputs": [],
      "source": [
        "#create image of each channel\n",
        "def image_mat(newdf):\n",
        "    im_matrices = []\n",
        "    blank_m = np.zeros((pxm,pxm))\n",
        "    if emp_value !=0:\n",
        "        blank_m[:]=emp_value\n",
        "    for zz in range(2, newdf.shape[1]):\n",
        "        im_matrix=blank_m.copy()\n",
        "        im_matrix[newdf[0].astype(int),\n",
        "              newdf[1].astype(int)] = newdf[zz]\n",
        "        im_matrices.append(im_matrix)\n",
        "    im_matrices = np.stack(im_matrices)\n",
        "    return im_matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1xWNhXn7PmZ"
      },
      "outputs": [],
      "source": [
        "#dataset of channel wise expantion images\n",
        "list_image=[]\n",
        "for i in range(2,aai.shape[1]):\n",
        "    dfn=aai[[0,1,i]]\n",
        "    #print(dfn)\n",
        "    newdf=newsamp(dfn,i)\n",
        "    img_15=image_mat(newdf)\n",
        "    list_image.append(img_15)\n",
        "gene_data=np.stack(list_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP5dxtmR7Pma"
      },
      "outputs": [],
      "source": [
        "# generate proper format for images\n",
        "from numpy import moveaxis\n",
        "import numpy as np\n",
        "ch_image=[]\n",
        "for i in range(gene_data.shape[0]):\n",
        "    data = moveaxis(gene_data[i], 0, 2)\n",
        "    ch_image.append(data)\n",
        "img_data=np.stack(ch_image)#Final image data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E-NDC747Pmb"
      },
      "outputs": [],
      "source": [
        "print(img_data.shape)\n",
        "plt.imshow(img_data[0,:,:,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is for the classification of data."
      ],
      "metadata": {
        "id": "aefQac5_c2F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U tensorflow-addons"
      ],
      "metadata": {
        "id": "GWyc0c-68KOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moDX_OKG7Pmb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Divide data into train test data\n",
        "Y = to_categorical(YY)\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    img_data, YY, test_size=0.2, random_state=23, stratify=YY)\n",
        "#x_train.shape"
      ],
      "metadata": {
        "id": "SmoIPy2KBEpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(np.unique(YY))\n",
        "input_shape = (64, 64, img_data.shape[3])"
      ],
      "metadata": {
        "id": "aTAA5ARc8o7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vision Transformer code can be read from following link https://keras.io/examples/vision/image_classification_with_vision_transformer/"
      ],
      "metadata": {
        "id": "HbRHpoiEdlo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "hzS6fS918o-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches"
      ],
      "metadata": {
        "id": "shxj87iB8pAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(4, 4))\n",
        "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
        "plt.imshow(image[:,:,0])\n",
        "#plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "PKGInc1y8pCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded"
      ],
      "metadata": {
        "id": "tB86zC4g8pEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_classifier():\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    #augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)( inputs)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.1)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.1)\n",
        "    # Classify outputs.\n",
        "    logits = layers.Dense(num_classes)(features)\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model"
      ],
      "metadata": {
        "id": "HnzO6Uu-8pGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0001\n",
        "weight_decay = 0.001\n",
        "batch_size = 30\n",
        "num_epochs = 10\n",
        "image_size = 64  # We'll resize input images to this size\n",
        "patch_size = 8 # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 8\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 8\n",
        "mlp_head_units = [2048,1024]  # Size of the dense layers of the final classifier"
      ],
      "metadata": {
        "id": "cufllNkb845a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(model):\n",
        "    optimizer = tfa.optimizers.AdaBelief(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(img_data, YY)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "vit_classifier = create_vit_classifier()\n",
        "history = run_experiment(vit_classifier)"
      ],
      "metadata": {
        "id": "C1OQAzMg848h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# demonstration of calculating metrics for a neural network model using sklearn\n",
        "from sklearn.datasets import make_circles\n",
        "from imblearn.metrics import specificity_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "yhat_classes = vit_classifier.predict(img_data, verbose=0)\n",
        "y_t = yhat_classes[:, 1]\n",
        "x_c=np.argmax(yhat_classes,axis=1)\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(YY,x_c)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(YY, x_c,average='macro')\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(YY, x_c,average='macro')\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(YY, x_c,average='macro')\n",
        "print('F1 score: %f' % f1)\n",
        "# specificity= tn/(fp+tn)\n",
        "specificity=specificity_score(YY, x_c, average='macro')\n",
        "print('specificity: %f' % specificity)\n",
        "# kappa\n",
        "kappa = cohen_kappa_score(YY, x_c)\n",
        "print('Cohens kappa: %f' % kappa)\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(Y, yhat_classes)\n",
        "print('ROC AUC: %f' % auc)\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(YY, x_c)\n",
        "print(matrix)\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "plt.rcParams.update({'font.size': 22})\n",
        "fig1, ax = plot_confusion_matrix(conf_mat=matrix, figsize=(6, 6), )\n",
        "plt.xlabel('Predictions Class', fontsize=18)\n",
        "plt.ylabel('Actual Class', fontsize=18)\n",
        "plt.title('confusion_matrix', fontsize=23)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Muo1kYNt85Fn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}